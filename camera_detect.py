#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”µæ¢¯æŒ‰é’®æ‘„åƒå¤´å®æ—¶æ£€æµ‹è„šæœ¬

å¤§å§å§ä¸“ç”¨ç‰ˆæœ¬ - é›Œå°é¬¼ç‰¹åˆ¶ ğŸ€
ç›´æ¥è¿è¡Œå³å¯ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œç”µæ¢¯æŒ‰é’®æ£€æµ‹
"""

import cv2
import sys
from pathlib import Path
from typing import Optional, Dict, Any
import argparse
import time

# å°è¯•å¯¼å…¥å¿…è¦çš„åº“
try:
    from ultralytics import YOLO
    import torch
    import numpy as np
except ImportError as e:
    print(f"âŒ å¯¼å…¥åº“å¤±è´¥: {e}")
    print("ğŸ“¦ è¯·å®‰è£…å¿…è¦çš„ä¾èµ–:")
    print("    pip install ultralytics opencv-python torch")
    sys.exit(1)


class CameraElevatorDetector:
    """æ‘„åƒå¤´ç”µæ¢¯æŒ‰é’®æ£€æµ‹å™¨ - é›Œå°é¬¼ç‰ˆ ğŸ€"""
    
    def __init__(self, model_path: Optional[str] = None, conf_threshold: float = 0.5) -> None:
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤YOLOæ¨¡å‹
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.conf_threshold = conf_threshold
        self.model = self._load_model(model_path)
        self.fps_counter = 0
        self.fps_start_time = time.time()
        
    def _load_model(self, model_path: Optional[str]) -> YOLO:
        """åŠ è½½YOLOæ¨¡å‹"""
        try:
            if model_path and Path(model_path).exists():
                print(f"ğŸ€ åŠ è½½è‡ªå®šä¹‰æ¨¡å‹: {model_path}")
                return YOLO(model_path)
            else:
                print("ğŸ€ ä½¿ç”¨é»˜è®¤YOLOv8æ¨¡å‹ (å¦‚éœ€æ›´å¥½æ•ˆæœè¯·è®­ç»ƒä¸“é—¨çš„ç”µæ¢¯æŒ‰é’®æ¨¡å‹)")
                return YOLO('yolov8n.pt')  # ä½¿ç”¨nanoç‰ˆæœ¬ï¼Œé€Ÿåº¦æ›´å¿«
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            sys.exit(1)
    
    def detect_frame(self, frame: np.ndarray) -> tuple[np.ndarray, Dict[str, Any]]:
        """
        æ£€æµ‹å•å¸§å›¾åƒä¸­çš„ç”µæ¢¯æŒ‰é’®
        
        Args:
            frame: è¾“å…¥å¸§
            
        Returns:
            æ£€æµ‹ç»“æœå¸§å’Œç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # è¿›è¡Œæ£€æµ‹
            results = self.model(frame, conf=self.conf_threshold, verbose=False)
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            annotated_frame = results[0].plot()
            
            # æå–æ£€æµ‹ä¿¡æ¯
            detections = results[0].boxes
            stats = {
                "total_detections": len(detections) if detections is not None else 0,
                "confidences": detections.conf.cpu().numpy().tolist() if detections is not None else [],
                "classes": detections.cls.cpu().numpy().tolist() if detections is not None else [],
                "class_names": [self.model.names[int(cls)] for cls in detections.cls.cpu().numpy()] if detections is not None else []
            }
            
            return annotated_frame, stats
            
        except Exception as e:
            print(f"âŒ æ£€æµ‹å‡ºé”™: {e}")
            return frame, {"error": str(e)}
    
    def calculate_fps(self) -> float:
        """è®¡ç®—FPS"""
        self.fps_counter += 1
        if self.fps_counter % 30 == 0:  # æ¯30å¸§è®¡ç®—ä¸€æ¬¡FPS
            current_time = time.time()
            fps = 30 / (current_time - self.fps_start_time)
            self.fps_start_time = current_time
            return fps
        return 0.0
    
    def run_camera_detection(self, camera_id: int = 0, show_fps: bool = True) -> None:
        """
        è¿è¡Œæ‘„åƒå¤´å®æ—¶æ£€æµ‹
        
        Args:
            camera_id: æ‘„åƒå¤´IDï¼Œé»˜è®¤ä¸º0
            show_fps: æ˜¯å¦æ˜¾ç¤ºFPS
        """
        print("ğŸ€ é›Œå°é¬¼å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹ä¸­...")
        print("ğŸ“¹ æŒ‰ 'q' é”®é€€å‡ºï¼ŒæŒ‰ 's' é”®æˆªå›¾ï¼ŒæŒ‰ 'c' é”®åˆ‡æ¢ç½®ä¿¡åº¦æ˜¾ç¤º")
        
        # æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(camera_id)
        
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
            print("ğŸ’¡ å°è¯•å…¶ä»–æ‘„åƒå¤´ID (1, 2, 3...)")
            return
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("âœ… æ‘„åƒå¤´å¯åŠ¨æˆåŠŸï¼")
        print(f"ğŸ¯ å½“å‰ç½®ä¿¡åº¦é˜ˆå€¼: {self.conf_threshold}")
        
        show_confidence = True
        screenshot_counter = 0
        
        try:
            while True:
                # è¯»å–å¸§
                ret, frame = cap.read()
                if not ret:
                    print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    break
                
                # è¿›è¡Œæ£€æµ‹
                result_frame, stats = self.detect_frame(frame)
                
                # æ·»åŠ ä¿¡æ¯æ–‡æœ¬
                info_text = []
                
                # FPSä¿¡æ¯
                if show_fps:
                    fps = self.calculate_fps()
                    if fps > 0:
                        info_text.append(f"FPS: {fps:.1f}")
                
                # æ£€æµ‹ç»Ÿè®¡
                if "error" not in stats:
                    info_text.append(f"æ£€æµ‹åˆ°æŒ‰é’®: {stats['total_detections']}")
                    
                    if show_confidence and stats['total_detections'] > 0:
                        max_conf = max(stats['confidences']) if stats['confidences'] else 0
                        info_text.append(f"æœ€é«˜ç½®ä¿¡åº¦: {max_conf:.2f}")
                
                # ç»˜åˆ¶ä¿¡æ¯æ–‡æœ¬
                y_offset = 30
                for text in info_text:
                    cv2.putText(result_frame, text, (10, y_offset), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    y_offset += 25
                
                # æ·»åŠ æ§åˆ¶è¯´æ˜
                cv2.putText(result_frame, "Press 'q':quit, 's':screenshot, 'c':toggle confidence", 
                          (10, result_frame.shape[0] - 10), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # æ˜¾ç¤ºç»“æœ
                cv2.imshow("ğŸ€ é›Œå°é¬¼çš„ç”µæ¢¯æŒ‰é’®æ£€æµ‹", result_frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q'):
                    print("ğŸ‘‹ å¤§å§å§å†è§ï½")
                    break
                elif key == ord('s'):
                    screenshot_counter += 1
                    filename = f"elevator_detection_screenshot_{screenshot_counter:03d}.jpg"
                    cv2.imwrite(filename, result_frame)
                    print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
                elif key == ord('c'):
                    show_confidence = not show_confidence
                    status = "å¼€å¯" if show_confidence else "å…³é—­"
                    print(f"ğŸ”„ ç½®ä¿¡åº¦æ˜¾ç¤ºå·²{status}")
        
        except KeyboardInterrupt:
            print("\nâš ï¸  æ£€æµ‹è¢«ç”¨æˆ·ä¸­æ–­")
        
        finally:
            # æ¸…ç†èµ„æº
            cap.release()
            cv2.destroyAllWindows()
            print("âœ… æ‘„åƒå¤´èµ„æºå·²é‡Šæ”¾")


def main() -> None:
    """ä¸»ç¨‹åºå…¥å£"""
    parser = argparse.ArgumentParser(
        description="ğŸ€ é›Œå°é¬¼çš„ç”µæ¢¯æŒ‰é’®æ‘„åƒå¤´æ£€æµ‹å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
    python camera_detect.py                           # ä½¿ç”¨é»˜è®¤è®¾ç½®
    python camera_detect.py --model best.pt          # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
    python camera_detect.py --conf 0.3 --camera 1   # è°ƒæ•´å‚æ•°
        """
    )
    
    parser.add_argument(
        "--model", "-m", 
        type=str, 
        default=None,
        help="æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.ptæ ¼å¼)"
    )
    
    parser.add_argument(
        "--conf", "-c", 
        type=float, 
        default=0.5,
        help="ç½®ä¿¡åº¦é˜ˆå€¼ (0.1-1.0ï¼Œé»˜è®¤0.5)"
    )
    
    parser.add_argument(
        "--camera", 
        type=int, 
        default=0,
        help="æ‘„åƒå¤´ID (é»˜è®¤0)"
    )
    
    parser.add_argument(
        "--no-fps", 
        action="store_true",
        help="ä¸æ˜¾ç¤ºFPSä¿¡æ¯"
    )
    
    args = parser.parse_args()
    
    # å‚æ•°éªŒè¯
    if not 0.1 <= args.conf <= 1.0:
        print("âŒ ç½®ä¿¡åº¦é˜ˆå€¼å¿…é¡»åœ¨0.1-1.0ä¹‹é—´")
        sys.exit(1)
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    print("=" * 50)
    print("ğŸ€ é›Œå°é¬¼çš„ç”µæ¢¯æŒ‰é’®æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 50)
    print(f"ğŸ“¹ æ‘„åƒå¤´ID: {args.camera}")
    print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {args.conf}")
    print(f"ğŸ“Š æ˜¾ç¤ºFPS: {not args.no_fps}")
    if args.model:
        print(f"ğŸ¤– æ¨¡å‹æ–‡ä»¶: {args.model}")
    else:
        print("ğŸ¤– ä½¿ç”¨é»˜è®¤YOLOæ¨¡å‹")
    print("=" * 50)
    
    # åˆ›å»ºæ£€æµ‹å™¨å¹¶è¿è¡Œ
    detector = CameraElevatorDetector(
        model_path=args.model, 
        conf_threshold=args.conf
    )
    
    detector.run_camera_detection(
        camera_id=args.camera, 
        show_fps=not args.no_fps
    )


if __name__ == "__main__":
    main()
